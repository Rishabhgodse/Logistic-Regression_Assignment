{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APA4C6lrA0Xi"
      },
      "outputs": [],
      "source": [
        "# What is Logistic Regression, and how does it differ from Linear Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a classification algorithm used when the dependent variable is categorical (binary or multiclass). Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts probabilities of class membership.\n",
        "\n",
        "Linear Regression is used for regression tasks, and it predicts continuous values.\n",
        "Logistic Regression is used for classification tasks, and it predicts the probability of a data point belonging to a particular class.\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# Dummy data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y_reg = np.array([10, 15, 20, 25, 30])   # Linear target\n",
        "y_clf = np.array([0, 0, 1, 1, 1])        # Classification target\n",
        "\n",
        "# Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X, y_reg)\n",
        "print(f\"Linear Regression Prediction: {linear_model.predict([[6]])}\")\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X, y_clf)\n",
        "print(f\"Logistic Regression Prediction: {logistic_model.predict_proba([[6]])}\")\n"
      ],
      "metadata": {
        "id": "5rGP0aKAFIp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the mathematical equation of Logistic Regression?"
      ],
      "metadata": {
        "id": "zGOnSYMVA6tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical equation for Logistic Regression is based on the sigmoid function:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝜎\n",
        "(\n",
        "𝑧\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "𝑒\n",
        "−\n",
        "𝑧\n",
        ",\n",
        " where\n",
        "𝑧\n",
        "=\n",
        "𝑤\n",
        "𝑇\n",
        "𝑥\n",
        "+\n",
        "𝑏\n",
        "P(y=1∣x)=σ(z)=\n",
        "1+e\n",
        "−z\n",
        "\n",
        "1\n",
        "​\n",
        " , where z=w\n",
        "T\n",
        " x+b\n",
        "Where:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑥\n",
        ")\n",
        "P(y=1∣x) is the probability that the target class is 1, given the input\n",
        "𝑥\n",
        "x.\n",
        "𝑤\n",
        "𝑇\n",
        "𝑥\n",
        "+\n",
        "𝑏\n",
        "w\n",
        "T\n",
        " x+b is the linear combination of input features.\n",
        "𝜎\n",
        "(\n",
        "𝑧\n",
        ")\n",
        "σ(z) is the sigmoid function.\n",
        "import numpy as np\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "z = np.linspace(-10, 10, 100)\n",
        "sigmoid_values = sigmoid(z)\n"
      ],
      "metadata": {
        "id": "smlUtqjrFJXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Why do we use the Sigmoid function in Logistic Regression?"
      ],
      "metadata": {
        "id": "GH73MPTmA6qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sigmoid function transforms the linear output into a probability value between 0 and 1, which is essential for binary classification. The sigmoid curve helps model the probability of the input belonging to class 1 or class 0:\n",
        "\n",
        "𝜎\n",
        "(\n",
        "𝑧\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "𝑒\n",
        "−\n",
        "𝑧\n",
        "σ(z)=\n",
        "1+e\n",
        "−z\n",
        "\n",
        "1\n",
        "​\n",
        "\n",
        "This maps any real-valued number into the (0, 1) range.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the sigmoid function\n",
        "plt.plot(z, sigmoid_values)\n",
        "plt.title('Sigmoid Function')\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('sigmoid(z)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kc48bG3jFJ9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the cost function of Logistic Regression?"
      ],
      "metadata": {
        "id": "q2dg68vPA6mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cost function for Logistic Regression is the log loss or binary cross-entropy:\n",
        "\n",
        "Cost\n",
        "(\n",
        "ℎ\n",
        "(\n",
        "𝑥\n",
        ")\n",
        ",\n",
        "𝑦\n",
        ")\n",
        "=\n",
        "−\n",
        "[\n",
        "𝑦\n",
        "log\n",
        "⁡\n",
        "(\n",
        "ℎ\n",
        "(\n",
        "𝑥\n",
        ")\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑦\n",
        ")\n",
        "log\n",
        "⁡\n",
        "(\n",
        "1\n",
        "−\n",
        "ℎ\n",
        "(\n",
        "𝑥\n",
        ")\n",
        ")\n",
        "]\n",
        "Cost(h(x),y)=−[ylog(h(x))+(1−y)log(1−h(x))]\n",
        "This function penalizes wrong predictions and helps the model learn the correct parameters.\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "y_true = [0, 0, 1, 1]\n",
        "y_pred = [0.1, 0.4, 0.35, 0.8]\n",
        "loss = log_loss(y_true, y_pred)\n",
        "print(f\"Log Loss: {loss}\")\n"
      ],
      "metadata": {
        "id": "MJbSAUlmFKnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is Regularization in Logistic Regression? Why is it needed?"
      ],
      "metadata": {
        "id": "N6XVs77FA6jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization adds a penalty to the cost function to prevent the model from overfitting by discouraging large coefficients. The two most common types are:\n",
        "\n",
        "L1 Regularization (Lasso): Adds the sum of the absolute values of the coefficients as a penalty.\n",
        "L2 Regularization (Ridge): Adds the sum of the squared values of the coefficients as a penalty.\n",
        "Need: Regularization prevents overfitting by reducing model complexity, ensuring that the model generalizes well to unseen data.\n",
        "\n",
        "Regularization Terms:\n",
        "L1 Regularization:\n",
        "𝜆\n",
        "∑\n",
        "∣\n",
        "𝑤\n",
        "𝑗\n",
        "∣\n",
        "λ∑∣w\n",
        "j\n",
        "​\n",
        " ∣\n",
        "L2 Regularization:\n",
        "𝜆\n",
        "∑\n",
        "𝑤\n",
        "𝑗\n",
        "2\n",
        "λ∑w\n",
        "j\n",
        "2\n",
        "​\n",
        "\n",
        "# L1 regularization (Lasso)\n",
        "logistic_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "logistic_l1.fit(X, y_clf)\n",
        "\n",
        "# L2 regularization (Ridge)\n",
        "logistic_l2 = LogisticRegression(penalty='l2')\n",
        "logistic_l2.fit(X, y_clf)\n",
        "\n",
        "print(f\"L1 Regularization Coefficients: {logistic_l1.coef_}\")\n",
        "print(f\"L2 Regularization Coefficients: {logistic_l2.coef_}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2bz0G4b5FLra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain the difference between Lasso, Ridge, and Elastic Net regression."
      ],
      "metadata": {
        "id": "Vq1Yb6MpA6gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso Regression (L1): Shrinks some coefficients to exactly zero, useful for feature selection.\n",
        "Ridge Regression (L2): Penalizes large coefficients but doesn’t set any to zero.\n",
        "Elastic Net: Combines both L1 and L2 penalties.\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
        "elastic_net.fit(X, y_reg)\n",
        "print(f\"Elastic Net Coefficients: {elastic_net.coef_}\")\n"
      ],
      "metadata": {
        "id": "smVrgwbVFMN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the impact of the regularization parameter (λ) in Logistic Regression?"
      ],
      "metadata": {
        "id": "-Gr0YM9UA6a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The regularization parameter (λ) controls the strength of the regularization:\n",
        "\n",
        "A small λ allows the model to fit the training data closely, possibly leading to overfitting. A large λ penalizes the weights more, reducing overfitting but potentially underfitting the data."
      ],
      "metadata": {
        "id": "dPB1YPWzFNS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the key assumptions of Logistic Regression?"
      ],
      "metadata": {
        "id": "HmM0vqQzA6YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linearity: The relationship between the independent variables and the log-odds is linear.\n",
        "Independence: The observations are independent of each other.\n",
        "No multicollinearity: Independent variables should not be highly correlated.\n"
      ],
      "metadata": {
        "id": "Uevg9Y96FOYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are some alternatives to Logistic Regression for classification tasks?"
      ],
      "metadata": {
        "id": "UrSJPv2sA6VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees\n",
        "Random Forests\n",
        "Support Vector Machines (SVM)\n",
        "k-Nearest Neighbors (KNN)\n",
        "Gradient Boosting Classifiers (e.g., XGBoost)"
      ],
      "metadata": {
        "id": "4hOZnsZoFPA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are Classification Evaluation Metrics?"
      ],
      "metadata": {
        "id": "yeWPIOVAA6SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-Score\n",
        "\n",
        "ROC AUC Score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_true = [0, 1, 1, 0, 1]\n",
        "y_pred = [0, 0, 1, 0, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "dLWRFpkBFPnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How does class imbalance affect Logistic Regression?"
      ],
      "metadata": {
        "id": "vETTkZBLA6P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the presence of class imbalance, Logistic Regression might be biased towards the majority class. This can be handled by:\n",
        "\n",
        "Using class weights (class_weight='balanced' in scikit-learn).\n",
        "Using oversampling or undersampling techniques."
      ],
      "metadata": {
        "id": "IwtRndRiFQMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is Hyperparameter Tuning in Logistic Regression?"
      ],
      "metadata": {
        "id": "Zo3J1bLSA6NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning involves selecting the optimal values for parameters like the regularization strength (λ). This can be done using techniques like Grid Search or Randomized Search.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X, y_clf)\n",
        "print(f\"Best parameters: {grid.best_params_}\")\n"
      ],
      "metadata": {
        "id": "9G1vb2zjFReY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are different solvers in Logistic Regression? Which one should be used?"
      ],
      "metadata": {
        "id": "Dt3bAHdKA6KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "liblinear: For small datasets; supports L1 regularization.\n",
        "lbfgs: For larger datasets; faster convergence.\n",
        "saga: For large datasets; supports both L1 and L2 regularization."
      ],
      "metadata": {
        "id": "4miJ6RdcFSDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How is Logistic Regression extended for multiclass classification?"
      ],
      "metadata": {
        "id": "ygAbQFs1A6He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is extended to multiclass classification using:\n",
        "\n",
        "One-vs-Rest (OvR): Fits one classifier per class.\n",
        "Softmax Regression (Multinomial): Generalizes to multiple classes by predicting probabilities for each class directly."
      ],
      "metadata": {
        "id": "zzqN1gSBFSnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the advantages and disadvantages of Logistic Regression?"
      ],
      "metadata": {
        "id": "U4LDpCOlA6Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages: Simple, interpretable, probabilistic output, efficient.\n",
        "Disadvantages: Assumes linearity, not suitable for complex relationships."
      ],
      "metadata": {
        "id": "STkgYJDOFTOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are some use cases of Logistic Regression?"
      ],
      "metadata": {
        "id": "cVOGv_g2A5_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting whether a customer will churn (binary classification).\n",
        "Medical diagnosis (e.g., predicting the probability of a disease).\n",
        "Email classification (spam vs. not spam).\n"
      ],
      "metadata": {
        "id": "kV8VpmQKFUWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the difference between Softmax Regression and Logistic Regression?"
      ],
      "metadata": {
        "id": "_vAwR0PSA5zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression: Used for binary classification.\n",
        "Softmax Regression: Used for multiclass classification, where the output probabilities sum up to 1 across all classes."
      ],
      "metadata": {
        "id": "vQevNz5bFU67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?"
      ],
      "metadata": {
        "id": "UHr5H7rNE7wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OvR: Builds a binary classifier for each class.\n",
        "Softmax: Handles multiclass directly in a single model, more efficient for multiclass tasks.\n"
      ],
      "metadata": {
        "id": "ZqjpGD0BFWFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we interpret coefficients in Logistic Regression?"
      ],
      "metadata": {
        "id": "7HyCgEt1FBFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients in Logistic Regression represent the change in the log-odds of the outcome for a unit change in the predictor. The exponentiated coefficient\n",
        "𝑒\n",
        "𝑤\n",
        "𝑗\n",
        "e\n",
        "w\n",
        "j\n",
        "​\n",
        "\n",
        "  gives the odds ratio.\n",
        "\n",
        "  coef = logistic_model.coef_[0]\n",
        "odds_ratios = np.exp(coef)\n",
        "print(f\"Odds Ratios: {odds_ratios}\")\n"
      ],
      "metadata": {
        "id": "IIa5-3-FFWsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#                                                                          Practical"
      ],
      "metadata": {
        "id": "d28pKsXGK-hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.?"
      ],
      "metadata": {
        "id": "pIodVdezexO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "VZqTpOI1e_nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.?"
      ],
      "metadata": {
        "id": "q8HUKzHyfARj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# L1 Regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"L1 Regularization Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "JHNONVbgfGmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "4LSh-dsPfK-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# L2 Regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy and coefficients\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"L2 Regularization Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Model Coefficients: {model.coef_}\")\n"
      ],
      "metadata": {
        "id": "RrhdsqF7fTdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "6B9XaPvyfWBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Elastic Net Regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Elastic Net Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "Ovu9lBPpffqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "CBaBhJWqfimU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Multiclass Logistic Regression with OvR\n",
        "model = LogisticRegression(multi_class='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Multiclass (OvR) Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "ZIgWIdVifn66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "5f6YRqV_fqUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "best_params = grid_search.best_params_\n",
        "accuracy = grid_search.best_score_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "ICsJ94UXfvP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "sr5MhZl-fy0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "\n",
        "# Print the average accuracy\n",
        "print(f\"Average Accuracy: {scores.mean():.2f}\")\n"
      ],
      "metadata": {
        "id": "TsjwXP8jhr3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "FV_FqPlKhuVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Assuming the last column is the target and the rest are features\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "_UZz_UHghx2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy?"
      ],
      "metadata": {
        "id": "QNl_YQDOi9ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_distributions = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Apply RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(model, param_distributions, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "best_params = random_search.best_params_\n",
        "accuracy = random_search.best_score_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "5HHKDn3mjCBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "p-oD05mNjFM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-vs-One Logistic Regression\n",
        "model = OneVsOneClassifier(LogisticRegression())\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"One-vs-One Logistic Regression Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "0heV6A70jLt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "XC6ggN_hjOnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and visualize confusion matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qjVvWVLujVE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "gGQle0-NjXC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate metrics\n",
        "y_pred = model.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "_Ga0EdXWjfBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "n_bxh7QwjjKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with class weights\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on Imbalanced Data: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "JA4bX6JwjnHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."
      ],
      "metadata": {
        "id": "psxalEG0jsUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Titanic dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Feature selection and preprocessing\n",
        "df = df[['Pclass', 'Sex', 'Age', 'Fare', 'Survived']].dropna()\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Age'] = imputer.fit_transform(df[['Age']])\n",
        "\n",
        "X = df[['Pclass', 'Sex', 'Age', 'Fare']]\n",
        "y = df['Survived']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on Titanic Data: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "yF6XH8pvjxOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "XWWD0TRNj1fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression()\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Logistic Regression with scaling\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy without Scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy with Scaling: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "id": "Oc3IN9n_j7ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "NltH2NRnj-E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "id": "9rIjiij1kC_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."
      ],
      "metadata": {
        "id": "XDUfJl6rkGCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression with C=0.5\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "2qm7jJ0VkLat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "Mion6754kNdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Identify important features based on coefficients\n",
        "feature_importance = np.abs(model.coef_[0])\n",
        "important_features = np.argsort(feature_importance)[::-1]\n",
        "\n",
        "print(f\"Feature Coefficients: {model.coef_}\")\n",
        "print(f\"Most Important Features (in order): {important_features}\")\n"
      ],
      "metadata": {
        "id": "xq-nB4BwmbiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score."
      ],
      "metadata": {
        "id": "6MDW2-Apmde6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate using Cohen's Kappa Score\n",
        "y_pred = model.predict(X_test)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "5F4fxlTcmwra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "yD0qS2cumzNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and plot Precision-Recall curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qhx9ofxfm5d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."
      ],
      "metadata": {
        "id": "AcLw4wptm-Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with different solvers\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=5000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {solver} solver: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "uOhN6SX3nDta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "vsKZDOO9nG_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate using MCC\n",
        "y_pred = model.predict(X_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.2f}\")\n"
      ],
      "metadata": {
        "id": "Qjwe5CuqnLw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "bs5eMplWnOP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy on raw data: {accuracy_raw:.2f}\")\n",
        "print(f\"Accuracy on standardized data: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "id": "onCNnif9nTax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "5X_PjIZMnXGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with different C values\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    print(f\"Accuracy with C={C}: {scores.mean():.2f}\")\n"
      ],
      "metadata": {
        "id": "SbwzXD0hnbXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "Ya0-ZhjOnebq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "\n",
        "# Load the model from the file\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "\n",
        "# Make predictions and evaluate accuracy\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Loaded Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "yVXw-CFMnhww"
      }
    }
  ]
}